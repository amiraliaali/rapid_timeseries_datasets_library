{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets.tsc_datasets import univariate, multivariate\n",
    "\n",
    "print(\"Univariate datasets:\", univariate)\n",
    "print(\"Multivariate datasets:\", multivariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.datasets import load_classification\n",
    "X, y, meta_data = load_classification(\"GunPoint\", return_metadata=True)\n",
    "print(\" Shape of X = \", X.shape)\n",
    "print(\" Meta data = \", meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "for idx in range(X.shape[0]):\n",
    "    for t in range(X.shape[2]):\n",
    "        records.append({\n",
    "            \"series\": idx,\n",
    "            \"time_idx\": t,\n",
    "            \"value\": X[idx, 0, t],\n",
    "            \"label\": y[idx]\n",
    "        })\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "import time\n",
    "start = time.time()\n",
    "max_encoder_length = 50\n",
    "max_prediction_length = 10\n",
    "\n",
    "dataset = TimeSeriesDataSet(\n",
    "    df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"value\",\n",
    "    group_ids=[\"series\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"label\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"series\"])\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"Dataset loading time: {end - start:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "dataloader = dataset.to_dataloader(batch_size=64)\n",
    "batch = next(iter(dataloader))\n",
    "end = time.time()\n",
    "print(f\"Preprocessing and batch extraction time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "mem_before = process.memory_info().rss / 1e6\n",
    "dataset = TimeSeriesDataSet(\n",
    "    df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"value\",\n",
    "    group_ids=[\"series\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"label\"],    target_normalizer=GroupNormalizer(groups=[\"series\"])\n",
    ")\n",
    "mem_after = process.memory_info().rss / 1e6\n",
    "print(f\"Memory used by dataset: {mem_after - mem_before:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalers = {\n",
    "    \"my_continuous_feature\": StandardScaler()\n",
    "}\n",
    "\n",
    "dataset = TimeSeriesDataSet(\n",
    "    data=df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[\"series\"],\n",
    "    max_encoder_length=24,\n",
    "    max_prediction_length=6,\n",
    "    time_varying_unknown_reals=[\"my_continuous_feature\"],\n",
    "    scalers=scalers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "mem_before = process.memory_info().rss / 1e6\n",
    "\n",
    "start = time.time()\n",
    "dataset = TimeSeriesDataSet(\n",
    "    data=df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[\"series\"],\n",
    "    max_encoder_length=30,\n",
    "    max_prediction_length=7,\n",
    "    time_varying_unknown_reals=[\"target\"],\n",
    "    randomize_length=(0.8, 1.0)\n",
    ")\n",
    "creation_time = time.time() - start\n",
    "\n",
    "dataloader = dataset.to_dataloader(batch_size=64)\n",
    "start = time.time()\n",
    "for batch in dataloader:\n",
    "    pass\n",
    "iteration_time = time.time() - start\n",
    "\n",
    "mem_after = process.memory_info().rss / 1e6\n",
    "\n",
    "print(f\"Dataset creation time: {creation_time:.2f}s\")\n",
    "print(f\"DataLoader iteration time: {iteration_time:.2f}s\")\n",
    "print(f\"Memory used: {mem_after - mem_before:.2f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "start = time.time()\n",
    "process = psutil.Process(os.getpid())\n",
    "mem_before = process.memory_info().rss / 1e6\n",
    "\n",
    "dataset = TimeSeriesDataSet(\n",
    "    data=df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[\"series\"],\n",
    "    max_encoder_length=2,\n",
    "    max_prediction_length=1,\n",
    "    time_varying_known_reals=[\"feature1\", \"feature2\"],\n",
    "    allow_missing_timesteps=True,\n",
    "    constant_fill_strategy={\n",
    "        \"feature1\": \"ffill\",\n",
    "        \"feature2\": \"bfill\",\n",
    "        \"target\": 0\n",
    "    }\n",
    ")\n",
    "creation_time = time.time() - start\n",
    "mem_after = process.memory_info().rss / 1e6\n",
    "\n",
    "print(f\"Dataset creation time: {creation_time:.4f}s\")\n",
    "print(f\"Memory used: {mem_after - mem_before:.2f}MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
